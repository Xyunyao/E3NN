{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e3nn\n",
    "#  |\n",
    "#  +-- o3        all about rotations and parity\n",
    "#  +-- nn        modules to make neural networks\n",
    "#  +-- io        utility classes for Spherical signals and Cartesian tensors\n",
    "\n",
    "# more info at https://docs.e3nn.org/en/stable/api/e3nn.html\n",
    "\n",
    "# The main class in e3nn.o3 is TensorProduct\n",
    "# TensorProduct is a pytorch Module\n",
    "\n",
    "# o3.TensorProduct                              general class to implement tensor products (optionally with parameters)\n",
    "# |\n",
    "# +-- o3.FullTensorProduct                      \"usual\" tensor product (with no parameters), give the two inputs and it deduce the outputs\n",
    "# +-- o3.FullyConnectedTensorProduct            define 2 inputs and output and it connects everything together\n",
    "# +-- o3.ElementwiseTensorProduct\n",
    "\n",
    "# more info at https://docs.e3nn.org/en/stable/api/o3/o3_tp.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "from functools import lru_cache\n",
    "from typing import Dict, List\n",
    "\n",
    "import e3nn.o3 as o3\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "#Get CG coefficients\n",
    "@lru_cache(maxsize=None)\n",
    "def get_clebsch_gordon(J: int, d_in: int, d_out: int, device) -> Tensor:\n",
    "    \"\"\" Get the (cached) Q^{d_out,d_in}_J matrices from equation (8) \"\"\"\n",
    "    return o3.wigner_3j(J, d_in, d_out, dtype=torch.float64, device=device).permute(2, 1, 0)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "J, d_in, d_out = 2, 1, 1\n",
    "clebsch_gordon_tensor = get_clebsch_gordon(J, d_in, d_out, device)\n",
    "print(clebsch_gordon_tensor.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([3, 1, 3])\n",
      "torch.Size([5, 1, 5])\n",
      "torch.Size([1, 3, 3])\n",
      "torch.Size([5, 3, 3])\n",
      "torch.Size([5, 3, 5])\n",
      "torch.Size([5, 3, 7])\n"
     ]
    }
   ],
   "source": [
    "@lru_cache(maxsize=None)\n",
    "def get_all_clebsch_gordon(max_degree: int, device) -> List[List[Tensor]]:\n",
    "    all_cb = []\n",
    "    for d_in in range(max_degree + 1):\n",
    "        for d_out in range(max_degree + 1):\n",
    "            K_Js = []\n",
    "            for J in range(abs(d_in - d_out), d_in + d_out + 1):\n",
    "                K_Js.append(get_clebsch_gordon(J, d_in, d_out, device))\n",
    "            all_cb.append(K_Js)\n",
    "    return all_cb\n",
    "\n",
    "cg_all = get_all_clebsch_gordon(2, device)\n",
    "\n",
    "\n",
    "print(len(cg_all))  # d_in=0, d_out=0, J=0\n",
    "print(cg_all[0][0].shape)  # d_in=0, d_out=0, J=0\n",
    "print(cg_all[1][0].shape)  # d_in=0, d_out=1, J=1\n",
    "#print(cg_all[0][2].shape)  # d_in=0, d_out=1, J=2\n",
    "print(cg_all[2][0].shape)  # d_in=0, d_out=2, J=2\n",
    "print(cg_all[3][0].shape)  # d_in=1, d_out=0, J=1\n",
    "print(cg_all[5][0].shape)  # d_in=1, d_out=2, J=1\n",
    "print(cg_all[5][1].shape)  # d_in=1, d_out=2, J=2\n",
    "print(cg_all[5][2].shape)  # d_in=1, d_out=2, J=3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.nvtx import range as nvtx_range\n",
    "\n",
    "def degree_to_dim(d):\n",
    "    if isinstance(d, int):\n",
    "        d = torch.tensor(d)\n",
    "    # Number of spherical harmonics coefficients for a given degree\n",
    "    return 2 * d + 1\n",
    "\n",
    "def get_spherical_harmonics(relative_pos: Tensor, max_degree: int) -> List[Tensor]:\n",
    "    all_degrees = list(range(2 * max_degree + 1))\n",
    "    with nvtx_range('spherical harmonics'):\n",
    "        sh = o3.spherical_harmonics(all_degrees, relative_pos, normalize=True)\n",
    "        return torch.split(sh, [degree_to_dim(d) for d in all_degrees], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spherical harmonics of degree 0: torch.Size([1, 1])\n",
      "tensor([[0.2821]])\n",
      "Spherical harmonics of degree 1: torch.Size([1, 3])\n",
      "tensor([[0.0000, 0.2185, 0.4370]])\n",
      "Spherical harmonics of degree 2: torch.Size([1, 5])\n",
      "tensor([[ 0.0000,  0.0000, -0.1262,  0.4370,  0.4370]])\n",
      "Spherical harmonics of degree 3: torch.Size([1, 7])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000, -0.3338,  0.0000,  0.5171,  0.4222]])\n",
      "Spherical harmonics of degree 4: torch.Size([1, 9])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000, -0.1693, -0.4282,  0.1514,  0.5664,\n",
      "          0.4005]])\n",
      "Spherical harmonics of degree 0:  (tensor([[0.2821]]), tensor([[0.0000, 0.2185, 0.4370]]), tensor([[ 0.0000,  0.0000, -0.1262,  0.4370,  0.4370]]), tensor([[ 0.0000,  0.0000,  0.0000, -0.3338,  0.0000,  0.5171,  0.4222]]), tensor([[ 0.0000,  0.0000,  0.0000,  0.0000, -0.1693, -0.4282,  0.1514,  0.5664,\n",
      "          0.4005]]))\n"
     ]
    }
   ],
   "source": [
    "# Define input: relative position tensor for one point in 3D\n",
    "relative_pos = torch.tensor([[0.0, 1.0, 2.0]])  # Shape: (1, 3)\n",
    "\n",
    "# Compute spherical harmonics up to max_degree = 2\n",
    "max_degree = 2\n",
    "\n",
    "# Get spherical harmonics\n",
    "spherical_harmonics = get_spherical_harmonics(relative_pos, max_degree)\n",
    "#print(spherical_harmonics)\n",
    "# Print the shape of the spherical harmonics\n",
    "for i, sh in enumerate(spherical_harmonics):\n",
    "    print(f\"Spherical harmonics of degree {i}: {sh.shape}\")\n",
    "    print(sh)\n",
    "\n",
    "\n",
    "print(\"Spherical harmonics of degree 0: \", spherical_harmonics[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def get_basis_script(max_degree: int,\n",
    "                     use_pad_trick: bool,\n",
    "                     spherical_harmonics: List[Tensor],\n",
    "                     clebsch_gordon: List[List[Tensor]],\n",
    "                     amp: bool) -> Dict[str, Tensor]:\n",
    "    \"\"\"\n",
    "    Compute pairwise bases matrices for degrees up to max_degree\n",
    "    :param max_degree:            Maximum input or output degree\n",
    "    :param use_pad_trick:         Pad some of the odd dimensions for a better use of Tensor Cores\n",
    "    :param spherical_harmonics:   List of computed spherical harmonics\n",
    "    :param clebsch_gordon:        List of computed CB-coefficients\n",
    "    :param amp:                   When true, return bases in FP16 precision\n",
    "    \"\"\"\n",
    "    basis = {}\n",
    "    idx = 0\n",
    "    # Double for loop instead of product() because of JIT script\n",
    "    for d_in in range(max_degree + 1):\n",
    "        for d_out in range(max_degree + 1):\n",
    "            key = f'{d_in},{d_out}'\n",
    "            K_Js = []\n",
    "            for freq_idx, J in enumerate(range(abs(d_in - d_out), d_in + d_out + 1)):\n",
    "                Q_J = clebsch_gordon[idx][freq_idx]\n",
    "                K_Js.append(torch.einsum('n f, k l f -> n l k', spherical_harmonics[J].float(), Q_J.float()))\n",
    "\n",
    "            basis[key] = torch.stack(K_Js, 2)  # Stack on second dim so order is n l f k\n",
    "            if amp:\n",
    "                basis[key] = basis[key].half()\n",
    "            if use_pad_trick:\n",
    "                basis[key] = F.pad(basis[key], (0, 1))  # Pad the k dimension, that can be sliced later\n",
    "\n",
    "            idx += 1\n",
    "\n",
    "    return basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basis(relative_pos: Tensor,\n",
    "              max_degree: int = 4,\n",
    "              compute_gradients: bool = False,\n",
    "              use_pad_trick: bool = False,\n",
    "              amp: bool = False) -> Dict[str, Tensor]:\n",
    "    with nvtx_range('spherical harmonics'):\n",
    "        spherical_harmonics = get_spherical_harmonics(relative_pos, max_degree)\n",
    "    with nvtx_range('CB coefficients'):\n",
    "        clebsch_gordon = get_all_clebsch_gordon(max_degree, relative_pos.device)\n",
    "\n",
    "    with torch.autograd.set_grad_enabled(compute_gradients):\n",
    "        with nvtx_range('bases'):\n",
    "            basis = get_basis_script(max_degree=max_degree,\n",
    "                                     use_pad_trick=use_pad_trick,\n",
    "                                     spherical_harmonics=spherical_harmonics,\n",
    "                                     clebsch_gordon=clebsch_gordon,\n",
    "                                     amp=amp)\n",
    "            return basis\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['0,0', '0,1', '0,2', '1,0', '1,1', '1,2', '2,0', '2,1', '2,2'])\n",
      "torch.Size([1, 1, 1, 3])\n",
      "torch.Size([1, 3, 3, 3])\n",
      "torch.Size([1, 3, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "basis = get_basis(relative_pos, max_degree=2, compute_gradients=True, use_pad_trick=False, amp=False)\n",
    "\n",
    "print(basis.keys())\n",
    "print(basis['0,1'].shape)  # d_in=0, d_out=1, J=1\n",
    "# explain, [batch, d_in,  num_of_J, d_out]\n",
    "print(basis['1,1'].shape)  # d_in=1, d_out=1 J=[0, 1, 2]\n",
    "print(basis['1,2'].shape)  # d_in=1, d_out=2  j=[1, 2, 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next step : how these bases are fused\n",
    "\n",
    "def degree_to_dim(degree: int) -> int:\n",
    "    return 2 * degree + 1\n",
    "\n",
    "@torch.jit.script\n",
    "def update_basis_with_fused(basis: Dict[str, Tensor],\n",
    "                            max_degree: int,\n",
    "                            use_pad_trick: bool,\n",
    "                            fully_fused: bool) -> Dict[str, Tensor]:\n",
    "    \"\"\" Update the basis dict with partially and optionally fully fused bases \"\"\"\n",
    "    num_edges = basis['0,0'].shape[0]\n",
    "    device = basis['0,0'].device\n",
    "    dtype = basis['0,0'].dtype\n",
    "    sum_dim = sum([degree_to_dim(d) for d in range(max_degree + 1)])\n",
    "\n",
    "    # Fused per output degree\n",
    "    for d_out in range(max_degree + 1):\n",
    "        sum_freq = sum([degree_to_dim(min(d, d_out)) for d in range(max_degree + 1)])\n",
    "        basis_fused = torch.zeros(num_edges, sum_dim, sum_freq, degree_to_dim(d_out) + int(use_pad_trick),\n",
    "                                  device=device, dtype=dtype)\n",
    "        acc_d, acc_f = 0, 0\n",
    "        for d_in in range(max_degree + 1):\n",
    "            basis_fused[:, acc_d:acc_d + degree_to_dim(d_in), acc_f:acc_f + degree_to_dim(min(d_out, d_in)),\n",
    "            :degree_to_dim(d_out)] = basis[f'{d_in},{d_out}'][:, :, :, :degree_to_dim(d_out)]\n",
    "\n",
    "            acc_d += degree_to_dim(d_in)\n",
    "            acc_f += degree_to_dim(min(d_out, d_in))\n",
    "\n",
    "        basis[f'out{d_out}_fused'] = basis_fused\n",
    "\n",
    "    # Fused per input degree\n",
    "    for d_in in range(max_degree + 1):\n",
    "        sum_freq = sum([degree_to_dim(min(d, d_in)) for d in range(max_degree + 1)])\n",
    "        basis_fused = torch.zeros(num_edges, degree_to_dim(d_in), sum_freq, sum_dim,\n",
    "                                  device=device, dtype=dtype)\n",
    "        acc_d, acc_f = 0, 0\n",
    "        for d_out in range(max_degree + 1):\n",
    "            basis_fused[:, :, acc_f:acc_f + degree_to_dim(min(d_out, d_in)), acc_d:acc_d + degree_to_dim(d_out)] \\\n",
    "                = basis[f'{d_in},{d_out}'][:, :, :, :degree_to_dim(d_out)]\n",
    "\n",
    "            acc_d += degree_to_dim(d_out)\n",
    "            acc_f += degree_to_dim(min(d_out, d_in))\n",
    "\n",
    "        basis[f'in{d_in}_fused'] = basis_fused\n",
    "\n",
    "    if fully_fused:\n",
    "        # Fully fused\n",
    "        # Double sum this way because of JIT script\n",
    "        sum_freq = sum([\n",
    "            sum([degree_to_dim(min(d_in, d_out)) for d_in in range(max_degree + 1)]) for d_out in range(max_degree + 1)\n",
    "        ])\n",
    "        basis_fused = torch.zeros(num_edges, sum_dim, sum_freq, sum_dim, device=device, dtype=dtype)\n",
    "\n",
    "        acc_d, acc_f = 0, 0\n",
    "        for d_out in range(max_degree + 1):\n",
    "            b = basis[f'out{d_out}_fused']\n",
    "            basis_fused[:, :, acc_f:acc_f + b.shape[2], acc_d:acc_d + degree_to_dim(d_out)] = b[:, :, :,\n",
    "                                                                                              :degree_to_dim(d_out)]\n",
    "            acc_f += b.shape[2]\n",
    "            acc_d += degree_to_dim(d_out)\n",
    "\n",
    "        basis['fully_fused'] = basis_fused\n",
    "\n",
    "    del basis['0,0']  # We know that the basis for l = k = 0 is filled with a constant\n",
    "    return basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['0,1', '0,2', '1,0', '1,1', '1,2', '2,0', '2,1', '2,2', 'out0_fused', 'out1_fused', 'out2_fused', 'in0_fused', 'in1_fused', 'in2_fused', 'fully_fused'])\n",
      "torch.Size([1, 9, 3, 1])\n",
      "torch.Size([1, 9, 7, 3])\n",
      "torch.Size([1, 3, 7, 9])\n",
      "torch.Size([1, 9, 19, 9])\n"
     ]
    }
   ],
   "source": [
    "updated_basis = update_basis_with_fused(basis, max_degree=2, use_pad_trick=False, fully_fused=True)\n",
    "print(updated_basis.keys())\n",
    "print(updated_basis['out0_fused'].shape)  # d_in=0,1,2 d_out=0, J=0\n",
    "#[batch, sum(d_to_dim(d_in)), num_of_J, d_out]\n",
    "print(updated_basis['out1_fused'].shape)  # d_in=0,1,2 d_out=1, J=[1],[0, 1, 2],[1,2, 3]\n",
    "print(updated_basis['in1_fused'].shape)  # d_in=1 d_out=0,1,2 J=[1],[0, 1, 2],[1,2, 3]\n",
    "#[batch, sum(d_to_dim(d_in)), num_of_J, sum(d_to_dim(d_out))]\n",
    "print(updated_basis['fully_fused'].shape)  # d_in=0,1,2 d_out=0,1,2 J=[0],[1],[2],[1],[0,1,2],[1,2,3],[2],[1,2,3],[0,1,2,3,4]\n",
    "# [batch, sum(d_to_dim(d_in)), num_of_J, sum(d_to_dim(d_out))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using Basis function to build message passing  \n",
    "source i (l order, 2l+1 dim), neighbour j (k order)  \n",
    "we need a W  in [2k+1, 2l+1] to brige k oder to l order  \n",
    "Che-Gordon * Y spherical harmonic can serve this purpose  \n",
    "Che-Gordon(l,k,J): [(2l+1)(2k+1),2J+1]-->can be veiwed as [2l+1, 2k+1, 2J+1]  \n",
    "Y for certain J with fixed l, k: [2J+1]  \n",
    "We can have J= |l-k|...l+k; for each J, Che-Gordon(l,k,J)*Y(J) ->[2l+1, 2k+1]  (basis shown above)  \n",
    "We further used invariant info in edge, such as ||xi-xj|| as input into MLP to learn a scale for J  \n",
    "Final message: learned sacler* Che-Gordon(l,k,J)*Y(J)  \n",
    "\n",
    "Consider channel_in, channel_out and num of J: the learned scaler forms a [channel_in, channel_out, num of J] matrix   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how the scalers are learned:\n",
    "import torch.nn as nn\n",
    "class RadialProfile(nn.Module):\n",
    "    \"\"\"\n",
    "    Radial profile function.\n",
    "    Outputs weights used to weigh basis matrices in order to get convolution kernels.\n",
    "    In TFN notation: $R^{l,k}$\n",
    "    In SE(3)-Transformer notation: $\\phi^{l,k}$\n",
    "\n",
    "    Note:\n",
    "        In the original papers, this function only depends on relative node distances ||x||.\n",
    "        Here, we allow this function to also take as input additional invariant edge features.\n",
    "        This does not break equivariance and adds expressive power to the model.\n",
    "\n",
    "    Diagram:\n",
    "        invariant edge features (node distances included) ───> MLP layer (shared across edges) ───> radial weights\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_freq: int,\n",
    "            channels_in: int,\n",
    "            channels_out: int,\n",
    "            edge_dim: int = 1,\n",
    "            mid_dim: int = 32,\n",
    "            use_layer_norm: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param num_freq:         Number of frequencies (number of J)\n",
    "        :param channels_in:      Number of input channels\n",
    "        :param channels_out:     Number of output channels\n",
    "        :param edge_dim:         Number of invariant edge features (input to the radial function)\n",
    "        :param mid_dim:          Size of the hidden MLP layers\n",
    "        :param use_layer_norm:   Apply layer normalization between MLP layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        modules = [\n",
    "            nn.Linear(edge_dim, mid_dim),\n",
    "            nn.LayerNorm(mid_dim) if use_layer_norm else None,\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mid_dim, mid_dim),\n",
    "            nn.LayerNorm(mid_dim) if use_layer_norm else None,\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mid_dim, num_freq * channels_in * channels_out, bias=False)\n",
    "        ]\n",
    "\n",
    "        self.net = nn.Sequential(*[m for m in modules if m is not None])\n",
    "\n",
    "    def forward(self, features: Tensor) -> Tensor:\n",
    "        return self.net(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all above to have the build block of convolution (message passaging)\n",
    "from enum import Enum\n",
    "class ConvSE3FuseLevel(Enum):\n",
    "    NONE = 0\n",
    "    OUT = 1\n",
    "    IN = 2\n",
    "    FULL = 3\n",
    "\n",
    "class VersatileConvSE3(nn.Module):\n",
    "    \"\"\"\n",
    "    Spherical convolution block.\n",
    "    In TFN notation: $C^{l,k}$\n",
    "    In SE(3)-Transformer notation: $\\phi^{l,k}$\n",
    "\n",
    "    Diagram:\n",
    "        input features ───> radial profile ───> basis matrices ───> fused basis ───> output features\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            max_degree: int,\n",
    "            channels_in: int,\n",
    "            channels_out: int,\n",
    "            edge_dim: int = 1,\n",
    "            mid_dim: int = 32,\n",
    "            use_pad_trick: bool = False,\n",
    "            fully_fused: bool = True,\n",
    "            amp: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param max_degree:       Maximum input or output degree\n",
    "        :param channels_in:      Number of input channels\n",
    "        :param channels_out:     Number of output channels\n",
    "        :param edge_dim:         Number of invariant edge features (input to the radial function)\n",
    "        :param mid_dim:          Size of the hidden MLP layers\n",
    "        :param use_pad_trick:    Pad some of the odd dimensions for a better use of Tensor Cores\n",
    "        :param fully_fused:      Use fully fused bases\n",
    "        :param amp:              When true, return bases in FP16 precision\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.max_degree = max_degree\n",
    "        self.use_pad_trick = use_pad_trick\n",
    "        self.fully_fused = fully_fused\n",
    "\n",
    "        # Radial profile function\n",
    "        self.radial_profile = RadialProfile(\n",
    "            num_freq=max_degree + 1,\n",
    "            channels_in=channels_in,\n",
    "            channels_out=channels_out,\n",
    "            edge_dim=edge_dim,\n",
    "            mid_dim=mid_dim,\n",
    "            use_layer_norm=True\n",
    "        )\n",
    "\n",
    "    def forward(self, features: Tensor, invariant_edge_feats: Tensor, basis: Tensor ) -> Tensor:\n",
    "        \"\"\"\n",
    "        :param features:         Input features (num_edges, channels_in, in_dim(2k+1))\n",
    "        :param invariant_edge_feats: Invariant edge features (batch_size, num_edges, edge_dim)\n",
    "        :param basis:          computed Basis matrices in differnt format (infused, outfused,fully_fused)\n",
    "        [batch_size, sum(d_to_dim(d_in)), num_of_J, sum(d_to_dim(d_out))]\n",
    "        :return:\n",
    "            Output features (batch_size, num_edges, channels_out)\n",
    "        \"\"\"\n",
    "        with nvtx_range(f'VersatileConvSE3'):\n",
    "            num_edges = features.shape[0]\n",
    "            in_dim = features.shape[2]\n",
    "            with nvtx_range(f'RadialProfile'):\n",
    "                radial_weights = self.radial_func(invariant_edge_feats) \\\n",
    "                    .view(-1, self.channels_out, self.channels_in * self.freq_sum)\n",
    "\n",
    "            if basis is not None:\n",
    "                # This block performs the einsum n i l, n o i f, n l f k -> n o k\n",
    "                # feature: n i l: num_edges, in_channels, in_dim (2l+1) # l is used for in order\n",
    "                # radial_wights: n o i f: num_edges, out_channels, in_channels, num_of_J\n",
    "                # basis: n l f k: num_edges, in_dims, num_of_J, out_dim (2k+1) # k is used for out order\n",
    "                # output: n o k: num_edges, out_channels, out_dim (2k+1) # k is used for out order\n",
    "                out_dim = basis.shape[-1]\n",
    "                if self.fuse_level != ConvSE3FuseLevel.FULL:\n",
    "                    out_dim += out_dim % 2 - 1  # Account for padded basis\n",
    "                basis_view = basis.view(num_edges, in_dim, -1) \n",
    "                tmp = (features @ basis_view).view(num_edges, -1, basis.shape[-1])\n",
    "                return (radial_weights @ tmp)[:, :, :out_dim]\n",
    "            else:\n",
    "                # k = l = 0 non-fused case\n",
    "                return radial_weights @ features\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SE3_Transformer attention caluclation\n",
    "# omitted due to the complexity of the code, but the general idea is to use TFN to generate K, V AND use\n",
    "# a linear layer to generate Q.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example usage of SE3_transformer\n",
    "from se3_transformer.model import SE3Transformer\n",
    "from se3_transformer.model.fiber import Fiber\n",
    "\n",
    "Fiber_in = Fiber({0:32})\n",
    "Fiber_hid = Fiber.create(num_degrees=2, num_channels=32)\n",
    "Fiber_out = Fiber.create(num_degrees=2, num_channels=32)\n",
    "test_se3_transformer = SE3Transformer(\n",
    "    num_layers=2,\n",
    "    fiber_in=Fiber_in,\n",
    "    fiber_hidden=Fiber_hid,\n",
    "    fiber_out =Fiber_out,\n",
    "    num_heads= 4,\n",
    "    channels_div =2,\n",
    "    fiber_edge= Fiber({}),\n",
    "    norm= True,\n",
    "    use_layer_norm=True,\n",
    "    tensor_cores=False,\n",
    "    low_memory= False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data from cached files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precomputing QM9 bases: 100%|██████████| 4089/4089 [00:43<00:00, 93.28it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13083 100000 17748\n",
      "{'pos': tensor([[-1.2700e-02,  1.0858e+00,  8.0000e-03],\n",
      "        [ 2.2000e-03, -6.0000e-03,  2.0000e-03],\n",
      "        [ 1.0117e+00,  1.4638e+00,  3.0000e-04],\n",
      "        [-5.4080e-01,  1.4475e+00, -8.7660e-01],\n",
      "        [-5.2380e-01,  1.4379e+00,  9.0640e-01]]), 'attr': tensor([[0., 1., 0., 0., 0., 6., 0., 0., 0., 0., 4.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])}\n",
      "(tensor([0, 0, 0, 0, 1, 2, 3, 4]), tensor([1, 2, 3, 4, 0, 0, 0, 0]))\n",
      "{'edge_attr': tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]])}\n",
      "dict_keys(['0,0', '0,1', '0,2', '0,3', '1,0', '1,1', '1,2', '1,3', '2,0', '2,1', '2,2', '2,3', '3,0', '3,1', '3,2', '3,3'])\n",
      "torch.Size([8, 1, 1, 2])\n",
      "torch.Size([8, 3, 3, 6])\n",
      "tensor([0.2821, 0.0000])\n",
      "tensor([-0.0008, -0.1545, -0.0012,  0.0000, -0.0021,  0.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# example usage of SE3_transformer for QM9 DATASET\n",
    "from se3_transformer.data_loading.qm9 import *\n",
    "\n",
    "qm9_dataset = QM9DataModule(data_dir='qm9',task='homo', batch_size=32, num_workers=4,num_degrees=4, precompute_bases=True)\n",
    "\n",
    "# exploare qm9 dataset: full data is randomaly divided into train test val\n",
    "print(len(qm9_dataset.ds_test), len(qm9_dataset.ds_train), len(qm9_dataset.ds_val))\n",
    "# data info: graph (containing node and edge features, target, basis for Se3_transformer)\n",
    "graph,y,basis=qm9_dataset.ds_train.dataset[0]\n",
    "# node information : 'pos' and 'attr'\n",
    "print(graph.ndata)\n",
    "#edge information: 'edge_attr'\n",
    "print(graph.edges()) # edge index\n",
    "print(graph.edata) # edge feature\n",
    "print(basis.keys()) # unfused basis\n",
    "print(basis['0,0'].shape) # num_edge, 2l+1, num_of_J, 2k+1+1 \n",
    "print(basis['1,2'].shape)\n",
    "print(basis['0,0'][0,0,0,:])\n",
    "print(basis['1,2'][0,0,0,:])\n",
    "\n",
    "\n",
    "# Load QM9 datase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=9, num_edges=14,\n",
      "      ndata_schemes={'pos': Scheme(shape=(3,), dtype=torch.float32), 'attr': Scheme(shape=(11,), dtype=torch.float32)}\n",
      "      edata_schemes={'edge_attr': Scheme(shape=(4,), dtype=torch.float32), 'rel_pos': Scheme(shape=(3,), dtype=torch.float32)})\n",
      "torch.Size([9, 6, 1])\n",
      "torch.Size([14, 4, 1])\n",
      "torch.Size([14, 1, 1, 2])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# transform QM9 data so that it's suitable for SE3_Transformer input\n",
    "# it's done by using  _collate function in the QM9DataModule \n",
    "def _get_relative_pos(qm9_graph: DGLGraph) -> Tensor:\n",
    "    x = qm9_graph.ndata['pos']\n",
    "    src, dst = qm9_graph.edges()\n",
    "    rel_pos = x[dst] - x[src] # [edge, 3]\n",
    "    return rel_pos\n",
    "\n",
    "# used as transform function in dataloader\n",
    "def _collate(samples):\n",
    "        graphs, y, *bases = map(list, zip(*samples))\n",
    "        batched_graph = dgl.batch(graphs)\n",
    "        edge_feats = {'0': batched_graph.edata['edge_attr'][..., None]} # edge feature is used as l0\n",
    "        batched_graph.edata['rel_pos'] = _get_relative_pos(batched_graph)\n",
    "        # get node features\n",
    "        node_feats = {'0': batched_graph.ndata['attr'][:, :6, None]} # node featere is used as l0 \n",
    "        #targets = (torch.cat(y) - self.targets_mean) / self.targets_std  # normalized targets value\n",
    "        targets = torch.cat(y)  # targets value\n",
    "        if bases:\n",
    "            # collate bases\n",
    "            all_bases = {\n",
    "                key: torch.cat([b[key] for b in bases[0]], dim=0)\n",
    "                for key in bases[0][0].keys()\n",
    "            }  # concatenate basis in the batch dimension\n",
    "\n",
    "            return batched_graph, node_feats, edge_feats, all_bases, targets\n",
    "        else:\n",
    "            return batched_graph, node_feats, edge_feats, targets\n",
    "        \n",
    "\n",
    "train_dataloader = _collate([qm9_dataset.ds_train.dataset[0], qm9_dataset.ds_train.dataset[1]])\n",
    "print(train_dataloader[0]) # batched graph\n",
    "print(train_dataloader[1]['0'].shape) # node features\n",
    "#print(test_collate[1]['1'].shape) # node features no l1 order feature\n",
    "print(train_dataloader[2]['0'].shape) # edge features also only l0 order\n",
    "print(train_dataloader[3]['0,0'].shape) # basis\n",
    "print(train_dataloader[4].shape) # basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=290, num_edges=602,\n",
      "      ndata_schemes={'pos': Scheme(shape=(3,), dtype=torch.float32), 'attr': Scheme(shape=(11,), dtype=torch.float32)}\n",
      "      edata_schemes={'edge_attr': Scheme(shape=(4,), dtype=torch.float32), 'rel_pos': Scheme(shape=(3,), dtype=torch.float32)})\n",
      "torch.Size([290, 6, 1])\n",
      "torch.Size([602, 4, 1])\n",
      "torch.Size([602, 1, 1, 2])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "train_dataloader= DataLoader(\n",
    "    qm9_dataset.ds_train,\n",
    "    batch_size=16,\n",
    "    collate_fn=qm9_dataset._collate,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "for batched_data in train_dataloader:\n",
    "\n",
    "    print(batched_data[0]) # batched graph\n",
    "    print(batched_data[1]['0'].shape) # node features\n",
    "    #print(test_collate[1]['1'].shape) # node features no l1 order feature\n",
    "    print(batched_data[2]['0'].shape) # edge features also only l0 order\n",
    "    print(batched_data[3]['0,0'].shape) # basis\n",
    "    print(batched_data[4].shape) # basis\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use qm9 data to train the test_se3_transformer model (we will use the pooled version)\n",
    "# write one iteration of training procedure\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from se3_transformer.model import SE3TransformerPooled\n",
    "from se3_transformer.model.fiber import Fiber\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "Fiber_in = Fiber({0:6}) # the in_fiber needs matching with the input node features\n",
    "Fiber_out = Fiber({0:32})#num_degrees=0, num_channels=32) # the out_fiber needs matching with the output node features\n",
    "num_edge_features = 4 # the edge features are used as l0 order\n",
    "test_se3_transformer = SE3TransformerPooled(\n",
    "    num_layers=2,\n",
    "    fiber_in=Fiber_in,\n",
    "    fiber_out =Fiber_out,\n",
    "    num_degrees=2,\n",
    "    num_channels=32,\n",
    "    num_heads= 4,\n",
    "    channels_div =2,\n",
    "    fiber_edge = Fiber({0: num_edge_features}),\n",
    "    output_dim= 1,\n",
    "    norm= True,\n",
    "    use_layer_norm=True,\n",
    "    tensor_cores=True,\n",
    "    low_memory= False,  \n",
    "    pooling='max'    \n",
    ")\n",
    "\n",
    "model = test_se3_transformer.to(device)\n",
    "\n",
    "def train(model:torch.nn.Module,\n",
    "          dataloader: DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module\n",
    "        ):\n",
    "    train_loss, train_acc = 0.0, 0.0\n",
    "    model.train()\n",
    "    for data in dataloader:\n",
    "        # Unpack the tuple\n",
    "        graph, node_feats, edge_feats, basis,target = data\n",
    "\n",
    "        # Move each element to the device\n",
    "        graph = graph.to(device)  # DGLGraph or similar object\n",
    "        node_feats = {k: v.to(device) for k, v in node_feats.items()}  # Dictionary of tensors\n",
    "        edge_feats = {k: v.to(device) for k, v in edge_feats.items()}  # Dictionary of tensors\n",
    "        basis = {k: v.to(device) for k, v in basis.items()}  # Optional dictionary of tensors\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(graph, node_feats, edge_feats, basis)\n",
    "        #forwad pass syntaxt(graph: DGLGraph, node_feats: Dict[str, Tensor],\n",
    "        #           edge_feats: Optional[Dict[str, Tensor]] = None,\n",
    "        #            basis: Optional[Dict[str, Tensor]] = None)\n",
    "        loss=loss_fn(output, target)\n",
    "        train_loss +=loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #train_acc = accuracy_fn(output, data.y)\n",
    "\n",
    "    train_loss = train_loss/len(dataloader)\n",
    "    #train_acc = train_acc/len(dataloader)\n",
    "\n",
    "    return train_loss\n",
    "    \n",
    "\n",
    "def accuracy_fn(output, target):\n",
    "    # pred = output.argmax(dim=1, keepdim=True)\n",
    "    # correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "    pass \n",
    "    #return correct / len(target)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yunyao/miniconda3/envs/SE3nv/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:352: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), \"Cannot convert view \" \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.1906\n",
      "Epoch 2, Loss: 0.1135\n",
      "Epoch 3, Loss: 0.0909\n",
      "Epoch 4, Loss: 0.0764\n",
      "Epoch 5, Loss: 0.0681\n",
      "Epoch 6, Loss: 0.0615\n",
      "Epoch 7, Loss: 0.0569\n",
      "Epoch 8, Loss: 0.0530\n",
      "Epoch 9, Loss: 0.0498\n",
      "Epoch 10, Loss: 0.0472\n"
     ]
    }
   ],
   "source": [
    "# training \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    train_loss = train(model, train_dataloader, optimizer, loss_fn)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {train_loss:.4f}\")\n",
    "    #print(f\"Epoch {epoch+1}, Accuracy: {train_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the model: 284641\n"
     ]
    }
   ],
   "source": [
    "# print the number of parameters in the model\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)  \n",
    "print(f\"Number of parameters in the model: {num_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'se3_transformer_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yunyao/miniconda3/envs/SE3nv/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:352: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), \"Cannot convert view \" \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0472\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "def test(model:torch.nn.Module,\n",
    "          dataloader: DataLoader,\n",
    "          loss_fn: torch.nn.Module\n",
    "        ):\n",
    "    test_loss, test_acc = 0.0, 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            graph, node_feats, edge_feats, basis,target = data\n",
    "\n",
    "            # Move each element to the device\n",
    "            graph = graph.to(device)  # DGLGraph or similar object\n",
    "            node_feats = {k: v.to(device) for k, v in node_feats.items()}  # Dictionary of tensors\n",
    "            edge_feats = {k: v.to(device) for k, v in edge_feats.items()}  # Dictionary of tensors\n",
    "            basis = {k: v.to(device) for k, v in basis.items()}  # Optional dictionary of tensors\n",
    "            target = target.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(graph, node_feats, edge_feats, basis)\n",
    "            #forwad pass syntaxt(graph: DGLGraph, node_feats: Dict[str, Tensor],\n",
    "            #           edge_feats: Optional[Dict[str, Tensor]] = None,\n",
    "            #            basis: Optional[Dict[str, Tensor]] = None)\n",
    "            loss=loss_fn(output, target)\n",
    "            test_loss +=loss\n",
    "        \n",
    "        test_loss = test_loss/len(dataloader)\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "# test the model\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    qm9_dataset.ds_test,\n",
    "    batch_size=16,\n",
    "    collate_fn=qm9_dataset._collate,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "test_loss = test(model, test_dataloader, loss_fn)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SE3nv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
